```{r}
N_pca_to_keep <- readRDS(file=fs::path(r_objects_folder, "062_N_pca_to_keep.rds"))
glmnet_res_93 <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_res_93.rds"))
glmnet_final_93  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_93.rds"))
glmnet_res_7 <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_res_7.rds"))
glmnet_final_7  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_7.rds"))
glmnet_res_14 <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_res_14.rds"))
glmnet_final_14  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_14.rds"))
glmnet_res_32 <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_res_32.rds"))
glmnet_final_32  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_32.rds"))
glmnet_res_rnj <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_res_rnj.rds"))
glmnet_final_rnj  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_rnj.rds"))

glmnet_final_93_rcs  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_93_rcs.rds"))
glmnet_final_7_rcs   <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_7_rcs.rds"))
glmnet_final_14_rcs  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_14_rcs.rds"))
glmnet_final_32_rcs  <- readRDS(file=fs::path(r_objects_folder, "070_glmnet_final_32_rcs.rds"))

rf_final_93  <- readRDS(file=fs::path(r_objects_folder, "070_rf_final_93.rds"))
rf_final_7   <- readRDS(file=fs::path(r_objects_folder, "070_rf_final_7.rds"))
rf_final_14  <- readRDS(file=fs::path(r_objects_folder, "070_rf_final_14.rds"))
rf_final_32  <- readRDS(file=fs::path(r_objects_folder, "070_rf_final_32.rds"))
```

# Cognitive slope - model fit

The elastic net models were fit on four variable sets across two modeling approaches:

-   The variable sets:

    -   The first `r N_pca_to_keep` PCA components from the set of 93 variables.

    -   The set of 7 PCA components from the 7 variables that had three or more votes from the expert panel

    -   The set of 14 PCA components from the 14 variables that had two or more votes from the expert panel

    -   The first `r N_pca_to_keep` PCA components from the 32 variables that had one or more votes from the expert panel

-   The models:

    -   original PCA components

    -   restricted cubic splines of the first `r N_pca_to_keep` PCA components

The random forest models were fit on four variable sets:

-   The variable sets:

    -   The first `r N_pca_to_keep` PCA components from the set of 93 variables.

    -   The set of 7 PCA components from the 7 variables that had three or more votes from the expert panel

    -   The set of 14 PCA components from the 14 variables that had two or more votes from the expert panel

    -   The first `r N_pca_to_keep` PCA components from the 32 variables that had one or more votes from the expert panel

Another elastic net model was proposed by RNJ.  The variables used were:

-   Age, GCP and lives alone.  Restricted cubic splines were added to the model.


**Model tuning**

The training data was into 10 cross-validation sets.

The models were tuned to minimize the RMSE.

The elastic net models were tuned using 25 sets of possible values.

These are the hyperparameters that were tuned:

-   Elastic net: alpha (mixture between lasso and ridge regression) and penalty term

The random forest models were tuned using 40 sets of possible values.

These are the hyperparameters that were tuned:

-   Random forest: number of trees and minimum sample size per node 

## GLMNET

### Original PCA components

<!-- These are the hyperparameters that have the best RMSE for the elastic net model: -->

<!-- Model using the first `r N_pca_to_keep` of 93 PCA components. -->

<!-- ```{r} -->
<!-- # collect_metrics(glm_res) -->
<!-- # collect_metrics(glmnet_res) -->
<!-- autoplot(glmnet_res_93) -->
<!-- show_best(glmnet_res_93, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the 7 PCA components from variables that had three or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_7) -->
<!-- show_best(glmnet_res_7, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the 14 PCA components from variables that had two or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_14) -->
<!-- show_best(glmnet_res_14, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the first `r N_pca_to_keep` of 32 PCA components from variables that had one or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_32) -->
<!-- show_best(glmnet_res_32, metric = "rmse") -->
<!-- ``` -->


```{r}

# fold1 <- glmnet_res_rnj %>%
#   slice(1) %>%
#   pull(splits)
# training_truth_fold1 <- testing(fold1[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 1)
# 
# fold2 <- glmnet_res_rnj %>%
#   slice(2) %>%
#   pull(splits)
# training_truth_fold2 <- testing(fold2[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 2)
# 
# fold3 <- glmnet_res_rnj %>%
#   slice(3) %>%
#   pull(splits)
# training_truth_fold3 <- testing(fold3[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 3)
# 
# fold4 <- glmnet_res_rnj %>%
#   slice(4) %>%
#   pull(splits)
# training_truth_fold4 <- testing(fold4[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 4)
# 
# fold5 <- glmnet_res_rnj %>%
#   slice(5) %>%
#   pull(splits)
# training_truth_fold5 <- testing(fold5[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 5)
# 
# fold6 <- glmnet_res_rnj %>%
#   slice(6) %>%
#   pull(splits)
# training_truth_fold6 <- testing(fold6[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 6)
# 
# fold7 <- glmnet_res_rnj %>%
#   slice(7) %>%
#   pull(splits)
# training_truth_fold7 <- testing(fold7[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 7)
# 
# fold8 <- glmnet_res_rnj %>%
#   slice(8) %>%
#   pull(splits)
# training_truth_fold8 <- testing(fold8[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 8)
# 
# fold9 <- glmnet_res_rnj %>%
#   slice(9) %>%
#   pull(splits)
# training_truth_fold9 <- testing(fold9[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 9)
# 
# fold10 <- glmnet_res_rnj %>%
#   slice(10) %>%
#   pull(splits)
# training_truth_fold10 <- testing(fold10[[1]]) %>%
#   select(vdgcp_slope72m) %>%
#   mutate(fold = 10)
# 
# training_truth <- training_truth_fold1 %>%
#   bind_rows(training_truth_fold2) %>%
#   bind_rows(training_truth_fold3) %>%
#   bind_rows(training_truth_fold4) %>%
#   bind_rows(training_truth_fold5) %>%
#   bind_rows(training_truth_fold6) %>%
#   bind_rows(training_truth_fold7) %>%
#   bind_rows(training_truth_fold8) %>%
#   bind_rows(training_truth_fold9) %>%
#   bind_rows(training_truth_fold10) 

glmnet_train_rnj <- collect_predictions(glmnet_res_rnj) %>%
  select(.row, .pred) %>%
  rename(.pred_rnj = .pred) %>%
  slice(1:436)

glmnet_train_7 <- collect_predictions(glmnet_res_7) %>%
  select(id, .row, .pred, vdgcp_slope72m) %>%
  rename(.pred_7 = .pred) %>%
  slice(1:436)

glmnet_train_14 <- collect_predictions(glmnet_res_14) %>%
  select(.row, .pred) %>%
  rename(.pred_14 = .pred) %>%
  slice(1:436)

glmnet_train_32 <- collect_predictions(glmnet_res_32) %>%
  select(.row, .pred) %>%
  rename(.pred_32 = .pred) %>%
  slice(1:436)

glmnet_train_93 <- collect_predictions(glmnet_res_93) %>%
  select(.row, .pred) %>%
  rename(.pred_93 = .pred) %>%
  slice(1:436)

foo <- glmnet_train_7 %>%
  left_join(glmnet_train_14, by = join_by(.row == .row)) %>%
  left_join(glmnet_train_32, by = join_by(.row == .row)) %>%
  left_join(glmnet_train_93, by = join_by(.row == .row)) %>%
  left_join(glmnet_train_rnj, by = join_by(.row == .row)) 


```

#### Performance in training set

Model using the first 7 of 93 PCA components.

```{r}
collect_metrics(glmnet_res_7) %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  select(.metric, mean) %>%
  group_by(.metric) %>%
  dplyr::summarize(mean = mean(mean))
cal_plot_regression(foo,
    truth = vdgcp_slope72m,
    estimate = .pred_7,
    alpha = .5
  ) +
  ggtitle("Elastic net - Training set (7 variables)") +
  hrbrthemes::theme_ipsum()
```

Model using the first 14 of 93 PCA components.

```{r}
collect_metrics(glmnet_res_14) %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  select(.metric, mean) %>%
  group_by(.metric) %>%
  dplyr::summarize(mean = mean(mean))
cal_plot_regression(foo,
    truth = vdgcp_slope72m,
    estimate = .pred_14,
    alpha = .5
  ) +
  ggtitle("Elastic net - Training set (14 variables)") +
  hrbrthemes::theme_ipsum()
```

Model using the first 32 of 93 PCA components.

```{r}
collect_metrics(glmnet_res_32) %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  select(.metric, mean) %>%
  group_by(.metric) %>%
  dplyr::summarize(mean = mean(mean))
cal_plot_regression(foo,
    truth = vdgcp_slope72m,
    estimate = .pred_32,
    alpha = .5
  ) +
  ggtitle("Elastic net - Training set (32 variables)") +
  hrbrthemes::theme_ipsum()
```

Model using all 93 PCA components.

```{r}
collect_metrics(glmnet_res_93) %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  select(.metric, mean) %>%
  group_by(.metric) %>%
  dplyr::summarize(mean = mean(mean))
cal_plot_regression(foo,
    truth = vdgcp_slope72m,
    estimate = .pred_93,
    alpha = .5
  ) +
  ggtitle("Elastic net - Training set (93 variables)") +
  hrbrthemes::theme_ipsum()
```

Model using the variables RNJ suggested.

```{r}
collect_metrics(glmnet_res_rnj) %>%
  filter(.metric %in% c("rmse", "rsq")) %>%
  select(.metric, mean) %>%
  group_by(.metric) %>%
  dplyr::summarize(mean = mean(mean))
cal_plot_regression(foo,
    truth = vdgcp_slope72m,
    estimate = .pred_rnj,
    alpha = .5
  ) +
  ggtitle("Elastic net - Training set (variables RNJ suggested)") +
  hrbrthemes::theme_ipsum()

```

#### Performance in testing set

Model using the first `r N_pca_to_keep` of 93 PCA components.

```{r}
collect_metrics(glmnet_final_93)
glmnet_final_93 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (93 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 7 PCA components from variables that had three or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_7)
glmnet_final_7 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (7 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 14 PCA components from variables that had two or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_14)
glmnet_final_14 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (14 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the first `r N_pca_to_keep` of 32 PCA components from variables that had one or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_32)
glmnet_final_32 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (32 variables)") +
  hrbrthemes::theme_ipsum()


```

### Restricted cubic splines

<!-- These are the hyperparameters that have the best RMSE for the elastic net model: -->

<!-- Model using the first `r N_pca_to_keep` of 93 PCA components. -->

<!-- ```{r} -->
<!-- # collect_metrics(glm_res_rcs) -->
<!-- # collect_metrics(glmnet_res_rcs) -->
<!-- autoplot(glmnet_res_93_rcs) -->
<!-- show_best(glmnet_res_93_rcs, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the 7 PCA components from variables that had three or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_7_rcs) -->
<!-- show_best(glmnet_res_7_rcs, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the 14 PCA components from variables that had two or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_14_rcs) -->
<!-- show_best(glmnet_res_14_rcs, metric = "rmse") -->
<!-- ``` -->

<!-- Model using the first `r N_pca_to_keep` of 32 PCA components from variables that had one or more votes from the expert panel. -->

<!-- ```{r} -->
<!-- autoplot(glmnet_res_32_rcs) -->
<!-- show_best(glmnet_res_32_rcs, metric = "rmse") -->
<!-- ``` -->

#### Performance in testing set

Model using the first `r N_pca_to_keep` of 93 PCA components.

```{r}
collect_metrics(glmnet_final_93_rcs)
glmnet_final_93_rcs %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (93 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 7 PCA components from variables that had three or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_7_rcs)
glmnet_final_7_rcs %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (7 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 14 PCA components from variables that had two or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_14_rcs)
glmnet_final_14_rcs %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (14 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the first `r N_pca_to_keep` of 32 PCA components from variables that had one or more votes from the expert panel.

```{r}
collect_metrics(glmnet_final_32_rcs)
glmnet_final_32_rcs %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - Testing set (32 variables)") +
  hrbrthemes::theme_ipsum()


```


## Random forest

### Original PCA components

#### Performance in testing set

Model using the first `r N_pca_to_keep` of 93 PCA components.

```{r}
collect_metrics(rf_final_93)
rf_final_93 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Random forest - Testing set (93 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 7 PCA components from variables that had three or more votes from the expert panel.

```{r}
collect_metrics(rf_final_7)
rf_final_7 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Random forest - Testing set (7 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the 14 PCA components from variables that had two or more votes from the expert panel.

```{r}
collect_metrics(rf_final_14)
rf_final_14 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Random forest - Testing set (14 variables)") +
  hrbrthemes::theme_ipsum()


```

Model using the first `r N_pca_to_keep` of 32 PCA components from variables that had one or more votes from the expert panel.

```{r}
collect_metrics(rf_final_32)
rf_final_32 %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Random forest - Testing set (32 variables)") +
  hrbrthemes::theme_ipsum()


```

## Elastic net - RNJ model

#### Performance in testing set

Model proposed by RNJ.

```{r}
collect_metrics(glmnet_final_rnj)
glmnet_final_rnj %>%
  collect_predictions() %>%
  cal_plot_regression(
    truth = vdgcp_slope72m,
    estimate = .pred,
    alpha = .5
  ) +
  ggtitle("Elastic net - RNJ model") +
  hrbrthemes::theme_ipsum()


```
